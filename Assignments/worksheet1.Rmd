---
title: "Your Turn!"
subtitle: "First brms model"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(diagram)
library(RColorBrewer)
library(reshape2)
library(curl)

mycols <- RColorBrewer::brewer.pal(8, "Dark2")

library(curl) 
# See https://github.com/mdnunez/encodingN200 for more information about the data
pdmdat <- curl("https://tinyurl.com/dataBayesCogMod")
pdm <- read.csv(pdmdat)

```

We will use a simple Perceptual Decision Making (PDM) data set throughout for the practical part. You can load it using the following code in `R`:

```{r, echo = T, eval = F}
install.packages('curl')  #You need to load the R package "curl" to use this cleaning code
library(curl) 
```

```{r echo = T}
# See https://github.com/mdnunez/encodingN200 for more information about the data
pdmdat <- curl("https://tinyurl.com/dataBayesCogMod")
pdm <- read.csv(pdmdat)
```


\vskip10mm

1. Familiarize yourself with the data. Maybe use a plot or two, see which variables might be relevant.

```{r}
knitr::kable(head(pdm[, -(1:2)]), format = "latex")
```

\vskip10mm

2. Suppose we wanted to model the accuracy of the responses using `brms`. As a first step, we will not use any predictors, but just model the responses provided and across incongruent and congruent trials. Here is the code (*warning:* this may take a while):

```{r brmodel-rt, cache=T, warning=FALSE, message=FALSE, echo = T, results='hide'}
library(brms)
priors <- c(prior_string("normal(0, 1)", class = "Intercept"))
model_fit <- brm(RT ~ 1
                 , data = pdm
                 , family = gaussian
                 , prior = priors
                 , chains = 2
                 , iter = 1500
                 , warmup = 750)
```
\vskip10mm

You can see an overview over the estimated parameters using

```{r echo = T}
summary(model_fit)
```

3. Let's make sense of the results. First, what does the line represent? What do the columns represent? Then, what dare the estimates and do they make sense?

\vskip10mm

4. Is this a good prior for response time? What would be better?

\newpage

Bonus. Suppose we wanted to model the accuracy of the responses using `brms`. As a first step, we will not use any predictors, but just model the responses provided and across incongruent and congruent trials. Here is the code (*warning:* this may take a while):

```{r brmodel-resp, cache=T, warning=FALSE, message=FALSE, echo = T, results='hide'}
library(brms)
priors <- c(prior_string("normal(0, 1)", class = "Intercept"))
model_fit <- brm(accuracy ~ 1
                 , data = pdm
                 , family = bernoulli(link = "logit")
                 , prior = priors
                 , chains = 2
                 , iter = 1500
                 , warmup = 750)
```
\vskip10mm

You can see an overview over the estimated parameters using

```{r echo = T}
summary(model_fit)
```

Let's again make sense of the results. Be careful to properly understand what the estimate of .78 represents. It is not the probability of responding accurately (the observed proportion of accurate responses is `r round(mean(pdm$accuracy), 2)`. (*hint*: try the `inv.logit` from the `gtools` package.)

```{r results='hide', eval = F}
library(gtools)
inv.logit(.78, min = 0, max = 1)
```
\vskip10mm

```{r, out.width = "15%", fig.align='right', echo = F}
knitr::include_graphics("../Slides/pics/do.png")
```